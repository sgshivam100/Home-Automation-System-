{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 150,
      "id": "7e82d33c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e82d33c",
        "outputId": "7a1cfea0-4e43-492a-8141-a4b48d846b40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ],
      "source": [
        "import json\n",
        "import math as m\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "id": "d358f14d",
      "metadata": {
        "id": "d358f14d"
      },
      "outputs": [],
      "source": [
        "#get words after filtering stop words\n",
        "def get_filtered_words(headline):\n",
        "    return [word for word in word_tokenize(headline) if not word in stop_words and not word.isdigit() and word != ',']\n",
        "\n",
        "# Build a vocab list from train dataset\n",
        "def build_vocab_list(train_dataset):\n",
        "    vocab_list = []\n",
        "    for record in train_dataset:\n",
        "        filtered_words = get_filtered_words(record['headline'])\n",
        "        vocab_list.extend(filtered_words)\n",
        "    return vocab_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "id": "013de925",
      "metadata": {
        "id": "013de925"
      },
      "outputs": [],
      "source": [
        "#create count frequency of words on training data\n",
        "def build_doc_freq_dict(train_dataset,categories):\n",
        "    word_frequency_dict = {category:{vocab:0 for vocab in vocab_list} for category in categories}\n",
        "    for record in train_dataset:\n",
        "        for word in get_filtered_words(record['headline']):\n",
        "            word_frequency_dict[record['category']][word]+=1\n",
        "    return word_frequency_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "id": "21ce3c80",
      "metadata": {
        "id": "21ce3c80"
      },
      "outputs": [],
      "source": [
        "# seperate dataset by class\n",
        "def get_data_group_by_classes(dataset):\n",
        "    seperated_category_dict = {category:[] for category in categories}\n",
        "    for record in dataset:\n",
        "        seperated_category_dict[record['category']].append(record)\n",
        "    return seperated_category_dict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_record_counts_per_category(separated_category_dict):\n",
        "    record_counts = {}\n",
        "    for category, records in separated_category_dict.items():\n",
        "        record_counts[category] = len(records)\n",
        "    return record_counts"
      ],
      "metadata": {
        "id": "riYaRPP0qT8d"
      },
      "id": "riYaRPP0qT8d",
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to acces to word count in respective category\n",
        "def get_word_count_in_category(word_counts_per_category, desired_category, desired_word):\n",
        "    if desired_category in word_counts_per_category:\n",
        "        category_word_counts = word_counts_per_category[desired_category]\n",
        "        if desired_word in category_word_counts:\n",
        "            return category_word_counts[desired_word]\n",
        "    return 0"
      ],
      "metadata": {
        "id": "bmhwQpwFyKM2"
      },
      "id": "bmhwQpwFyKM2",
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_words_counts_per_category(separated_category_dict):\n",
        "    word_counts_per_category = {}\n",
        "\n",
        "  # Iterate through each category and its records\n",
        "    for category, records in separated_category_dict.items():\n",
        "        word_counts = {}\n",
        "        for i, record in enumerate(records):\n",
        "            # Get filtered words from the headline for the current record\n",
        "            filtered_words = get_filtered_words(record['headline'])\n",
        "\n",
        "            #removing duplicate entries in filtered_words\n",
        "            filtered_words = list(set(filtered_words))\n",
        "\n",
        "            # Update word counts for this category\n",
        "            for word in filtered_words:\n",
        "                if word in word_counts:\n",
        "                    word_counts[word] += 1\n",
        "                else:\n",
        "                    word_counts[word] = 1\n",
        "        # Add the word counts for this category to the dictionary\n",
        "        word_counts_per_category[category] = word_counts\n",
        "    return word_counts_per_category\n"
      ],
      "metadata": {
        "id": "rrLScp7Jvihi"
      },
      "id": "rrLScp7Jvihi",
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "id": "b258ea54",
      "metadata": {
        "id": "b258ea54"
      },
      "outputs": [],
      "source": [
        "#checks if smoothing is needed (In case of Multinomial)\n",
        "def is_smoothing_needed(filterd_words,word_dict,category):\n",
        "    for word in filterd_words:\n",
        "        if word not in word_dict[category].keys():\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "# get probability of the text assuming conditional independence(Multinomail naive bayes)\n",
        "def get_naive_probability(category,text,word_dict,grouped_classes_dict,dataset):\n",
        "    if category not in word_dict.keys():\n",
        "        return\n",
        "    total_word_cond_prob = 1\n",
        "    filterd_words = get_filtered_words(text)\n",
        "    smoothing_indicator = is_smoothing_needed(filterd_words,word_dict,category)\n",
        "    for word in filterd_words:\n",
        "        if smoothing_indicator :\n",
        "            word_doc_freq = word_dict[category][word] if word in word_dict[category].keys() else 0\n",
        "            total_word_cond_prob *= ((word_doc_freq+1)/((len(grouped_classes_dict[category])+(len(vocab_list))))) # Smoothing technique\n",
        "        else:\n",
        "            total_word_cond_prob *= (word_dict[category][word]/len(grouped_classes_dict[category]))\n",
        "    class_probability = (len(grouped_classes_dict[category])/len(dataset))\n",
        "    return total_word_cond_prob * class_probability\n",
        "\n",
        "# get probability of the text assuming conditional independence(Multivariate naive bayes)\n",
        "def get_naive_probability_multivariate(category,text,word_dict,grouped_classes_dict,word_counts_per_category,record_counts,dataset):\n",
        "    if category not in word_dict.keys():\n",
        "        return\n",
        "    total_word_cond_prob = 1\n",
        "    filterd_words = get_filtered_words(text)\n",
        "    for word in filterd_words:\n",
        "            word_occurence = get_word_count_in_category(word_counts_per_category, category, word)\n",
        "            total_doucument_category = record_counts[category]\n",
        "            total_word_cond_prob *= ((word_occurence+1)/((total_doucument_category+2))) # Smoothing\n",
        "    class_probability = (len(grouped_classes_dict[category])/len(dataset))\n",
        "    return total_word_cond_prob * class_probability\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "id": "6bb6a9fb",
      "metadata": {
        "id": "6bb6a9fb"
      },
      "outputs": [],
      "source": [
        "#get the predicted class given text belong to (Multinomial)\n",
        "def get_predicted_class(categories,str_to_predict,word_frequency_dict,group_classes_dict,train_dataset):\n",
        "    greatest_prob = 0\n",
        "    predicted_category = ''\n",
        "    for category in categories:\n",
        "        total_word_cond_prob = 1\n",
        "        prob_of_category_contains_headline =  get_naive_probability(category,str_to_predict,word_frequency_dict,group_classes_dict,train_dataset)\n",
        "        if prob_of_category_contains_headline > greatest_prob:\n",
        "            greatest_prob = prob_of_category_contains_headline\n",
        "            predicted_category = category\n",
        "        #print(f'''prob_of_category_contains_headline {category} is {prob_of_category_contains_headline}''')\n",
        "    return predicted_category\n",
        "\n",
        "#get the predicted class given text belong to (Multivariate)\n",
        "def get_predicted_class_multivariate(categories,str_to_predict,word_frequency_dict,group_classes_dict,word_counts_per_category,record_counts,train_dataset):\n",
        "    greatest_prob = 0\n",
        "    predicted_category = ''\n",
        "    for category in categories:\n",
        "        total_word_cond_prob = 1\n",
        "        prob_of_category_contains_headline =  get_naive_probability_multivariate(category,str_to_predict,word_frequency_dict,group_classes_dict,word_counts_per_category,record_counts,train_dataset)\n",
        "        if prob_of_category_contains_headline > greatest_prob:\n",
        "            greatest_prob = prob_of_category_contains_headline\n",
        "            predicted_category = category\n",
        "        #print(f'''prob_of_category_contains_headline {category} is {prob_of_category_contains_headline}''')\n",
        "    return predicted_category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "id": "3f659eaa",
      "metadata": {
        "id": "3f659eaa"
      },
      "outputs": [],
      "source": [
        " #calculate the accuracy of the classifier over given dataset (Multinomial):\n",
        "def get_accuracy(dataset,categories,word_frequency_dict,group_classes_dict):\n",
        "\n",
        "    category_counts = {}\n",
        "    for record in dataset:\n",
        "        category = record['category']\n",
        "        predicted_category = get_predicted_class(categories,record['headline'],word_frequency_dict,group_classes_dict,dataset)\n",
        "        #print(f\"Predicted Category: {predicted_category}\")\n",
        "        if predicted_category == record['category']:\n",
        "            if category in category_counts:\n",
        "               category_counts[category] += 1\n",
        "            else:\n",
        "              category_counts[category] = 1\n",
        "\n",
        "    return category_counts"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #calculate the  accuracy of the classifier over given dataset (Multivariate) :\n",
        "def get_accuracy_multivariate(dataset,categories,word_frequency_dict,group_classes_dict,word_counts_per_category,record_counts):\n",
        "\n",
        "    category_counts = {}\n",
        "    for record in dataset:\n",
        "        category = record['category']\n",
        "        predicted_category = get_predicted_class_multivariate(categories,record['headline'],word_frequency_dict,group_classes_dict,word_counts_per_category,record_counts,dataset)\n",
        "        #print(f\"Predicted Category: {predicted_category}\")\n",
        "        if predicted_category == record['category']:\n",
        "            if category in category_counts:\n",
        "               category_counts[category] += 1\n",
        "            else:\n",
        "              category_counts[category] = 1\n",
        "    return category_counts"
      ],
      "metadata": {
        "id": "eIDLMTlcyX-h"
      },
      "id": "eIDLMTlcyX-h",
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "id": "1ba2c6d1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ba2c6d1",
        "outputId": "89a3117b-41e3-4159-91b2-d49d2b712957"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Number of records in the dataset: 57274\n",
            " Number of different categories in the dataset: 7\n"
          ]
        }
      ],
      "source": [
        "# Load the original dataset into dictionary and  data preprocessing.\n",
        "dataset = []\n",
        "categories = [\"BUSINESS\", \"COMEDY\", \"SPORTS\", \"CRIME\", \"RELIGION\", \"HEALTHY LIVING\", \"POLITICS\"]\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "with open('/content/news_category_dataset.json') as data:\n",
        "    for line_num, file_text in enumerate(data, start=0):\n",
        "        record = json.loads(file_text)\n",
        "\n",
        "        if record['category'] in categories:\n",
        "            processed_record = {\"category\": record['category'], \"headline\": record['headline'].lower()}\n",
        "            dataset.append(processed_record)\n",
        "no_of_records = len(dataset)\n",
        "print(f\"\"\" Number of records in the dataset: {no_of_records}\"\"\")\n",
        "print(f\"\"\" Number of different categories in the dataset: {len(categories)}\"\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "id": "ceca1ff3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceca1ff3",
        "outputId": "9c2f87cf-e42f-4775-e91e-30921cfa5a7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Number of records in the training dataset: 48682\n",
            " Number of records in the test dataset: 8592\n",
            "\n",
            " Category Wise Accuracy in Multinomial Naive classifier-->\n",
            "Category: BUSINESS, Accuracy: 62.42%\n",
            "Category: COMEDY, Accuracy: 73.15%\n",
            "Category: SPORTS, Accuracy: 79.28%\n",
            "Category: CRIME, Accuracy: 91.59%\n",
            "Category: RELIGION, Accuracy: 72.92%\n",
            "Category: HEALTHY LIVING, Accuracy: 63.19%\n",
            "Category: POLITICS, Accuracy: 71.09%\n",
            "Overall Accuracy of the Multinomial Naive Baye's Classifier over test dataset is 71.43% \n",
            "\n",
            " Category Wise Accuracy in Multivariate Naive classifier-->\n",
            "Category: BUSINESS, Accuracy: 28.83%\n",
            "Category: COMEDY, Accuracy: 27.35%\n",
            "Category: SPORTS, Accuracy: 33.06%\n",
            "Category: CRIME, Accuracy: 32.3%\n",
            "Category: RELIGION, Accuracy: 21.98%\n",
            "Category: HEALTHY LIVING, Accuracy: 46.64%\n",
            "Category: POLITICS, Accuracy: 89.97%\n",
            "Overall Accuracy of the Multivariate Naive Baye's Classifier over test dataset is 66.02%\n"
          ]
        }
      ],
      "source": [
        "#Divide the dataset into train and test data(test data set 15% and training dataset 85%)\n",
        "train_dataset,test_dataset = train_test_split(dataset,test_size=0.15)\n",
        "\n",
        "print(f\"\"\" Number of records in the training dataset: {len(train_dataset)}\"\"\")\n",
        "print(f\"\"\" Number of records in the test dataset: {len(test_dataset)}\"\"\")\n",
        "print()\n",
        "#Group all records with their respective category\n",
        "group_classes_dict = get_data_group_by_classes(train_dataset)\n",
        "#get no of records in respective category\n",
        "record_counts = get_record_counts_per_category(group_classes_dict)\n",
        "#Get count of records containing particular word in respective category (for multivariate)\n",
        "record_counts_category = get_words_counts_per_category(group_classes_dict)\n",
        "#vocabulary\n",
        "vocab_list = build_vocab_list(train_dataset)\n",
        "#frequency of each word category wise (For Multinomial)\n",
        "word_frequency_dict = build_doc_freq_dict(train_dataset,categories)\n",
        "\n",
        "#In test dataset to get no of records in each category (To calculate category wise accuracy)\n",
        "group_classes_dict_test = get_data_group_by_classes(test_dataset)\n",
        "record_counts_test = get_record_counts_per_category(group_classes_dict_test)\n",
        "\n",
        "#list containing category wise no of records  predicted correctly (Multinomial)\n",
        "test_accuracy = get_accuracy(test_dataset,categories,word_frequency_dict,group_classes_dict)\n",
        "#list containing category wise no of records  predicted correctly (Multivariate)\n",
        "test_accuracy_multivariate = get_accuracy_multivariate(test_dataset,categories,word_frequency_dict,group_classes_dict,record_counts_category,record_counts)\n",
        "\n",
        "\n",
        "overall_accuracy=0;\n",
        "print(f''' Category Wise Accuracy in Multinomial Naive classifier-->''')\n",
        "#calculating category wise accuracy and print it (Multinomial)\n",
        "for category, count in record_counts_test.items():\n",
        "  if category in test_accuracy_multivariate:\n",
        "    print(f\"Category: {category}, Accuracy: {round((test_accuracy_multivariate[category]/count)*100,2)}%\")\n",
        "    overall_accuracy+=round((test_accuracy_multivariate[category]/count)*100,2)*count\n",
        "accuracy_multivariate = round(overall_accuracy/len(test_dataset),2)\n",
        "\n",
        "print(f'''Overall Accuracy of the Multinomial Naive Baye's Classifier over test dataset is {accuracy_multivariate}% \\n''')\n",
        "\n",
        "overall_accuracy=0\n",
        "\n",
        "print(f''' Category Wise Accuracy in Multivariate Naive classifier-->''')\n",
        "#calculating category wise accuracy and print it (Multinomial)\n",
        "\n",
        "for category, count in record_counts_test.items():\n",
        "  if category in test_accuracy:\n",
        "    print(f\"Category: {category}, Accuracy: {round((test_accuracy[category]/count)*100,2)}%\")\n",
        "    overall_accuracy+=round((test_accuracy[category]/count)*100,2)*count\n",
        "accuracy_multinomial = round(overall_accuracy/len(test_dataset),2)\n",
        "\n",
        "print(f'''Overall Accuracy of the Multivariate Naive Baye's Classifier over test dataset is {accuracy_multinomial}%''')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}